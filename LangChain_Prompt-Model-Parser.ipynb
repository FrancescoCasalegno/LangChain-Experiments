{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "\n",
    "key = os.environ['OPENAI_API_KEY']\n",
    "assert key, \"Please set your OPENAI_API_KEY environment variable.\"\n",
    "openai.api_key = key"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(prompt: str, model: str = \"gpt-3.5-turbo\") -> str:\n",
    "    \"\"\"Use OpenAI API to generate text completion.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    prompt\n",
    "        The prompt to generate text completion for.\n",
    "    model\n",
    "        The LLM to use for generating text completion.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    str\n",
    "        The text completion generated by the LLM.\n",
    "    \"\"\"\n",
    "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
    "    response = openai.ChatCompletion.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0, \n",
    "    )\n",
    "    return response.choices[0].message[\"content\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1+1 equals 2.'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(\"What is 1+1?\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translate the text that is delimited by triple backticks into a style that is {output_style}.\n",
      "text: ```{input_text}```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\n",
    "Translate the text that is delimited by triple backticks into a style that is {output_style}.\n",
    "text: ```{input_text}```\n",
    "\"\"\"\n",
    "\n",
    "print(prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translate the text that is delimited by triple backticks into a style that is American English with a calm and polite tone.\n",
      "text: ```Tcheu, c'est pas vrai, ça ! Le machin pour la clim que vous m'avez vendu ne fonctionne pas ! Avec qui je dois parler pour me faire rembourser ???```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# fill prompt_template with values\n",
    "output_style = \"American English with a calm and polite tone\"\n",
    "input_text = \"Tcheu, c'est pas vrai, ça ! Le machin pour la clim que vous m'avez vendu ne fonctionne pas ! Avec qui je dois parler pour me faire rembourser ???\"\n",
    "\n",
    "prompt = prompt_template.format(output_style=output_style, input_text=input_text)\n",
    "\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Oh dear, this is quite frustrating! The air conditioning unit that you sold me doesn't seem to be working. Could you please let me know who I should speak to in order to request a refund? Thank you very much for your assistance.\""
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_completion(prompt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Prompts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_prompt_template = ChatPromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['input_text', 'output_style'], output_parser=None, partial_variables={}, template='\\nTranslate the text that is delimited by triple backticks into a style that is {output_style}.\\ntext: ```{input_text}```\\n', template_format='f-string', validate_template=True), additional_kwargs={})"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template.messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prompt=PromptTemplate(input_variables=['input_text', 'output_style'], output_parser=None, partial_variables={}, template='\\nTranslate the text that is delimited by triple backticks into a style that is {output_style}.\\ntext: ```{input_text}```\\n', template_format='f-string', validate_template=True) additional_kwargs={}\n",
      "{'prompt': PromptTemplate(input_variables=['input_text', 'output_style'], output_parser=None, partial_variables={}, template='\\nTranslate the text that is delimited by triple backticks into a style that is {output_style}.\\ntext: ```{input_text}```\\n', template_format='f-string', validate_template=True), 'additional_kwargs': {}}\n"
     ]
    }
   ],
   "source": [
    "print(chat_prompt_template.messages[0])\n",
    "print(vars(chat_prompt_template.messages[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['input_text', 'output_style']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_prompt_template.messages[0].prompt.input_variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "customer_messages = chat_prompt_template.format_messages(\n",
    "    input_text=input_text,\n",
    "    output_style=output_style,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HumanMessage(content=\"\\nTranslate the text that is delimited by triple backticks into a style that is American English with a calm and polite tone.\\ntext: ```Tcheu, c'est pas vrai, ça ! Le machin pour la clim que vous m'avez vendu ne fonctionne pas ! Avec qui je dois parler pour me faire rembourser ???```\\n\", additional_kwargs={}, example=False)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_messages[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Translate the text that is delimited by triple backticks into a style that is American English with a calm and polite tone.\n",
      "text: ```Tcheu, c'est pas vrai, ça ! Le machin pour la clim que vous m'avez vendu ne fonctionne pas ! Avec qui je dois parler pour me faire rembourser ???```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(customer_messages[0].content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "chat_model = ChatOpenAI(\n",
    "    model=\"gpt-3.5-turbo\",\n",
    "    temperature=0.0,\n",
    "    cache=None,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatOpenAI(cache=None, verbose=False, callbacks=None, callback_manager=None, tags=None, metadata=None, client=<class 'openai.api_resources.chat_completion.ChatCompletion'>, model_name='gpt-3.5-turbo', temperature=0.0, model_kwargs={}, openai_api_key='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', openai_api_base='', openai_organization='', openai_proxy='', request_timeout=None, max_retries=6, streaming=False, n=1, max_tokens=None, tiktoken_model_name=None)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chat_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Oh dear, this is quite frustrating! The air conditioning unit that you sold me isn't working at all. Could you please let me know who I should speak to in order to get a refund? Thank you very much for your assistance.\n"
     ]
    }
   ],
   "source": [
    "model_response = chat_model(customer_messages)\n",
    "print(model_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Parser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema, StructuredOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_abstract = \"\"\"\n",
    "Title: Randomized Clinical Trial Investigating the Efficacy of Drug Y in the Management of Type 2 Diabetes Mellitus\n",
    "\n",
    "Abstract:\n",
    "\n",
    "In this double-blind, randomized, placebo-controlled trial, we aimed to evaluate the effectiveness and safety of Drug Y in lowering glycated hemoglobin (HbA1c) levels in patients with type 2 diabetes mellitus. The study enrolled participants aged 45-75 years, with four hundreds patients receiving Drug Y and two hundreds patients receiving a placebo over a 24-week period.\n",
    "\n",
    "The primary endpoint was the change from baseline in HbA1c levels (measured in %) at 24 weeks. At the end of the trial, HbA1c levels had decreased by an average of 1.2% in the Drug Y group compared to a reduction of 0.2% in the placebo group (mean difference = -1.0%; 95% CI, -1.3 to -0.7; p<0.001).\n",
    "\n",
    "Secondary endpoints included changes in fasting plasma glucose levels (FPG), measured in mg/dL. Patients in the Drug Y group exhibited a mean reduction of 30.6 mg/dL in FPG levels compared to a reduction of 5.4 mg/dL in the placebo group (mean difference = -25.2 mg/dL; 95% CI, -28.1 to -22.3 mg/dL; p<0.001).\n",
    "\n",
    "Adverse events were reported in 14% of the participants taking Drug Y, and 10% in the placebo group, with the most common being mild hypoglycemia and gastrointestinal discomfort. Serious adverse events were similar in both groups.\n",
    "\n",
    "In conclusion, Drug Y significantly lowered HbA1c and FPG levels over 24 weeks in patients with type 2 diabetes, demonstrating a superior glycemic control compared to placebo, with a manageable safety profile. Future studies should focus on the long-term effects of Drug Y in managing type 2 diabetes.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "population_size_schema = ResponseSchema(\n",
    "    name=\"population_size\",\n",
    "    description=\"Total population size on which the study was performed, including both the treatment and control groups. \\\n",
    "        It should be expressed as an integer number, e.g. 100, not a string e.g. 'one hundred'. \\\n",
    "        If the population size is not found, set value to None.\",\n",
    "    type=\"int\",\n",
    "    )\n",
    "fpg_reduction_schema = ResponseSchema(\n",
    "    name=\"fpg_reduction\",\n",
    "    description=\"Reduction in fasting plasma glucose (FPG) levels in the treatment group compared to the control group. \\\n",
    "        It should be expressed as a float number followed by a measurement unit, e.g. '1.2 mg/L'. \\\n",
    "        If the FPG reduction is not found, set value to None.\",\n",
    "    type=\"str\",\n",
    "    )\n",
    "\n",
    "\n",
    "response_schemas = [\n",
    "    population_size_schema,\n",
    "    fpg_reduction_schema,\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "format_instructions = output_parser.get_format_instructions()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"population_size\": int  // Total population size on which the study was performed, including both the treatment and control groups.         It should be expressed as an integer number, e.g. 100, not a string e.g. 'one hundred'.         If the population size is not found, set value to None.\n",
      "\t\"fpg_reduction\": str  // Reduction in fasting plasma glucose (FPG) levels in the treatment group compared to the control group.         It should be expressed as a float number followed by a measurement unit, e.g. '1.2 mg/L'.         If the FPG reduction is not found, set value to None.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(format_instructions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "For the following paper abstract (identified by ABSTRACT_BEGIN and ABSTRACT_END), extract the following output:\n",
    "- population_size\n",
    "- fpg_reduction\n",
    "\n",
    "ABSTRACT_BEGIN\n",
    "{paper_abstract}\n",
    "ABSTRACT_END\n",
    "\n",
    "{format_instructions}\n",
    "\"\"\"\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=prompt_template)\n",
    "\n",
    "messages = prompt.format_messages(\n",
    "    paper_abstract=paper_abstract,\n",
    "    format_instructions=format_instructions,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "For the following paper abstract (identified by ABSTRACT_BEGIN and ABSTRACT_END), extract the following output:\n",
      "- population_size\n",
      "- fpg_reduction\n",
      "\n",
      "ABSTRACT_BEGIN\n",
      "\n",
      "Title: Randomized Clinical Trial Investigating the Efficacy of Drug Y in the Management of Type 2 Diabetes Mellitus\n",
      "\n",
      "Abstract:\n",
      "\n",
      "In this double-blind, randomized, placebo-controlled trial, we aimed to evaluate the effectiveness and safety of Drug Y in lowering glycated hemoglobin (HbA1c) levels in patients with type 2 diabetes mellitus. The study enrolled participants aged 45-75 years, with four hundreds patients receiving Drug Y and two hundreds patients receiving a placebo over a 24-week period.\n",
      "\n",
      "The primary endpoint was the change from baseline in HbA1c levels (measured in %) at 24 weeks. At the end of the trial, HbA1c levels had decreased by an average of 1.2% in the Drug Y group compared to a reduction of 0.2% in the placebo group (mean difference = -1.0%; 95% CI, -1.3 to -0.7; p<0.001).\n",
      "\n",
      "Secondary endpoints included changes in fasting plasma glucose levels (FPG), measured in mg/dL. Patients in the Drug Y group exhibited a mean reduction of 30.6 mg/dL in FPG levels compared to a reduction of 5.4 mg/dL in the placebo group (mean difference = -25.2 mg/dL; 95% CI, -28.1 to -22.3 mg/dL; p<0.001).\n",
      "\n",
      "Adverse events were reported in 14% of the participants taking Drug Y, and 10% in the placebo group, with the most common being mild hypoglycemia and gastrointestinal discomfort. Serious adverse events were similar in both groups.\n",
      "\n",
      "In conclusion, Drug Y significantly lowered HbA1c and FPG levels over 24 weeks in patients with type 2 diabetes, demonstrating a superior glycemic control compared to placebo, with a manageable safety profile. Future studies should focus on the long-term effects of Drug Y in managing type 2 diabetes.\n",
      "\n",
      "ABSTRACT_END\n",
      "\n",
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"population_size\": int  // Total population size on which the study was performed, including both the treatment and control groups.         It should be expressed as an integer number, e.g. 100, not a string e.g. 'one hundred'.         If the population size is not found, set value to None.\n",
      "\t\"fpg_reduction\": str  // Reduction in fasting plasma glucose (FPG) levels in the treatment group compared to the control group.         It should be expressed as a float number followed by a measurement unit, e.g. '1.2 mg/L'.         If the FPG reduction is not found, set value to None.\n",
      "}\n",
      "```\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(messages[0].content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = chat_model(messages)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "```json\n",
      "{\n",
      "\t\"population_size\": 600,\n",
      "\t\"fpg_reduction\": \"-25.2 mg/dL\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'population_size': 600, 'fpg_reduction': '-25.2 mg/dL'}\n"
     ]
    }
   ],
   "source": [
    "output_dict = output_parser.parse(response.content)\n",
    "print(output_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now a new parser, for the fpg reduction: separate numeric_value (float) from measurement_unit (str)\n",
    "value_schema = ResponseSchema(\n",
    "    name=\"value\",\n",
    "    description=\"Numerical value of measurement, e.g. for '-123.4 m/(kg*s^2)', the value is -123.4.\\\n",
    "        If the value is not found, set value to None.\",\n",
    "    type=\"float\",\n",
    "    )\n",
    "unit_schema = ResponseSchema(\n",
    "    name=\"unit\",\n",
    "    description=\"Measurement unit, e.g. for '-123.4 m/(kg*s^2)', the unit is 'm/(kg*s^2)'.\\\n",
    "        If the unit is not found, set value to None.\",\n",
    "    type=\"str\",\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "response_schemas = [\n",
    "    value_schema,\n",
    "    unit_schema,\n",
    "    ]\n",
    "\n",
    "fpg_reduction_parser = StructuredOutputParser.from_response_schemas(response_schemas)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-25.2 mg/dL\n"
     ]
    }
   ],
   "source": [
    "fpg_reduction = output_dict[\"fpg_reduction\"]\n",
    "print(fpg_reduction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"value\": float  // Numerical value of measurement, e.g. for '-123.4 m/(kg*s^2)', the value is -123.4.        If the value is not found, set value to None.\n",
      "\t\"unit\": str  // Measurement unit, e.g. for '-123.4 m/(kg*s^2)', the unit is 'm/(kg*s^2)'.        If the unit is not found, set value to None.\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "prompt_template = \"\"\"\\\n",
    "    For the following fpg reduction, extract the following output:\n",
    "    - value\n",
    "    - unit\n",
    "\n",
    "    fpg_reduction: {fpg_reduction}\n",
    "\n",
    "    {format_instructions}\n",
    "    \"\"\"\n",
    "\n",
    "format_instructions = fpg_reduction_parser.get_format_instructions()\n",
    "print(format_instructions)\n",
    "\n",
    "prompt = ChatPromptTemplate.from_template(template=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    For the following fpg reduction, extract the following output:\n",
      "    - value\n",
      "    - unit\n",
      "\n",
      "    fpg_reduction: -25.2 mg/dL\n",
      "\n",
      "    The output should be a markdown code snippet formatted in the following schema, including the leading and trailing \"```json\" and \"```\":\n",
      "\n",
      "```json\n",
      "{\n",
      "\t\"value\": float  // Numerical value of measurement, e.g. for '-123.4 m/(kg*s^2)', the value is -123.4.        If the value is not found, set value to None.\n",
      "\t\"unit\": str  // Measurement unit, e.g. for '-123.4 m/(kg*s^2)', the unit is 'm/(kg*s^2)'.        If the unit is not found, set value to None.\n",
      "}\n",
      "```\n",
      "    \n",
      "```json\n",
      "{\n",
      "\t\"value\": -25.2,\n",
      "\t\"unit\": \"mg/dL\"\n",
      "}\n",
      "```\n"
     ]
    }
   ],
   "source": [
    "messages = prompt.format_messages(\n",
    "    fpg_reduction=fpg_reduction,\n",
    "    format_instructions=format_instructions,\n",
    "    )\n",
    "print(messages[0].content)\n",
    "\n",
    "response = chat_model(messages)\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'value': -25.2, 'unit': 'mg/dL'}\n"
     ]
    }
   ],
   "source": [
    "fpg_reduction_dict = fpg_reduction_parser.parse(response.content)\n",
    "print(fpg_reduction_dict)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'population_size': 600, 'fpg_reduction': '-25.2 mg/dL'}\n",
      "{'population_size': 600, 'fpg_reduction': {'value': -25.2, 'unit': 'mg/dL'}}\n"
     ]
    }
   ],
   "source": [
    "print(output_dict)\n",
    "final_dict = {**output_dict}\n",
    "final_dict[\"fpg_reduction\"] = fpg_reduction_dict\n",
    "print(final_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"population_size\": 600,\n",
      "    \"fpg_reduction\": {\n",
      "        \"value\": -25.2,\n",
      "        \"unit\": \"mg/dL\"\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "\n",
    "print(json.dumps(final_dict, indent=4))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
