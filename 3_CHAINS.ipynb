{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chains\n",
    "\n",
    "- Using LLMs in isolation is fine for many applications.\n",
    "- But in some cases, it can be useful to use a **Chain**: a sequence of calls to components.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pprint import pprint\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Copy .env.example file as .env: `cp .env.example .env`\n",
    "# 2. Open .env file and set all the env variables\n",
    "load_dotenv(\".env\")\n",
    "OPENAI_KEY = os.getenv(\"OPENAI_KEY\")\n",
    "assert OPENAI_KEY, \"Please set your OPENAI_KEY environment variable.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LLM Chain\n",
    "- The `LLMChain` is the simplest chain, but it is also used for most other, more complex, chains.\n",
    "- It takes in a prompt template, formats it with the user input, and returns the response from an LLM.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.prompts import ChatPromptTemplate, PromptTemplate\n",
    "from langchain.chains import LLMChain\n",
    "from langchain.chains import SimpleSequentialChain\n",
    "from langchain.chains import SequentialChain\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Chat Model\n",
    "chat_model = ChatOpenAI(\n",
    "    openai_api_key=OPENAI_KEY,\n",
    "    model_name=\"gpt-4\",\n",
    "    temperature=0,\n",
    "    model_kwargs={\"top_p\":1},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = ChatPromptTemplate.from_template(\n",
    "    \"How would you describe the country {country} in a very short (max 4 line) rhyming poem?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = LLMChain(llm=chat_model, prompt=prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Land of the Alps, so grand and tall,\n",
      "Switzerland, the fairest of all. \n",
      "Where crystal lakes and chalets reside, \n",
      "A peaceful haven, world's pride.\n"
     ]
    }
   ],
   "source": [
    "print(chain.run(\"Switzerland\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sequential Chains\n",
    "\n",
    "- Sequential Chains feed the output of a chain as the input of a following chain.\n",
    "- `SimpleSequentialChain` ‚Äî allows for only single input and single output\n",
    "- `SequentialChain` ‚Äî allows for multiple inputs and outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_1 = ChatPromptTemplate.from_template(\n",
    "    \"How would you describe the country {country} in a very short (max 4 line) rhyming poem?\"\n",
    ")\n",
    "\n",
    "prompt_template_2 = ChatPromptTemplate.from_template(\n",
    "    \"Give a title to this poem: {poem}\"\n",
    ") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_1 = LLMChain(llm=chat_model, prompt=prompt_template_1)\n",
    "chain_2 = LLMChain(llm=chat_model, prompt=prompt_template_2)\n",
    "\n",
    "chain = SimpleSequentialChain(chains=[chain_1, chain_2], verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SimpleSequentialChain chain...\u001b[0m\n",
      "\u001b[36;1m\u001b[1;3mIn France, where romance and art dance,\n",
      "Fine wine flows, Eiffel Tower's glow enchants.\n",
      "History's majestic, fashion's quite drastic,\n",
      "Culture-rich land, its beauty fantastic.\u001b[0m\n",
      "\u001b[33;1m\u001b[1;3m\"Ode to the French Elegance\"\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\"Ode to the French Elegance\"'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"France\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 -> 2 --\\\n",
    "#           |--> 4\n",
    "#      3 --/\n",
    "\n",
    "prompt_template_1 = ChatPromptTemplate.from_template(\n",
    "    \"Translate the following into English: {raw_text}\"\n",
    ")\n",
    "\n",
    "prompt_template_2 = ChatPromptTemplate.from_template(\n",
    "    \"Summarize the following in one sentence: {en_text}\"\n",
    ") \n",
    "\n",
    "prompt_template_3 = ChatPromptTemplate.from_template(\n",
    "    \"Say what is the language of the following text: {raw_text}\"\n",
    ")\n",
    "\n",
    "prompt_template_4 = ChatPromptTemplate.from_template(\n",
    "    \"Expand the following text into bullet points written in {lang}: {summary_en_text}\"\n",
    ")\n",
    "\n",
    "\n",
    "chain_1 = LLMChain(llm=chat_model, prompt=prompt_template_1, output_key=\"en_text\")\n",
    "chain_2 = LLMChain(llm=chat_model, prompt=prompt_template_2, output_key=\"summary_en_text\")\n",
    "chain_3 = LLMChain(llm=chat_model, prompt=prompt_template_3, output_key=\"lang\")\n",
    "chain_4 = LLMChain(llm=chat_model, prompt=prompt_template_4, output_key=\"bullets_lang_text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "overall_chain = SequentialChain(\n",
    "    chains=[chain_1, chain_2, chain_3, chain_4],\n",
    "    input_variables=[\"raw_text\"],\n",
    "    output_variables=[\"en_text\", \"summary_en_text\", \"lang\", \"bullets_lang_text\"],\n",
    "    verbose=True,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new SequentialChain chain...\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "RAW_TEXT:\n",
      "\n",
      "La commune de Gen√®ve s'est constitu√©e sous sa forme actuelle en 1930, au moment de la fusion des \n",
      "communes de Gen√®ve (Gen√®ve-Cit√©), de Plainpalais, des Eaux-Vives et du Petit-Saconnex. Un projet \n",
      "supprimant la commune et mettant la ville sous la tutelle du canton √©choue devant le peuple genevois \n",
      "en d√©cembre 1926. Apr√®s la fusion, quatre arrondissements (portant les noms des anciennes communes)\n",
      "sont maintenus jusqu'en 1958, date √† laquelle, avec le processus de d√©peuplement du centre de la\n",
      "ville et de d√©placement de la population √† sa p√©riph√©rie, ils sont supprim√©s.\n",
      "\n",
      "Il appara√Æt, au d√©but du xxie si√®cle, qu'une distinction des t√¢ches de la ville et de celles du \n",
      "canton n'est toujours pas clairement r√©alis√©e. Dans ce contexte, le Conseil d'√âtat propose en 1999 \n",
      "une fusion entre ville et canton mais la ville, g√©r√©e par une majorit√© de gauche oppos√©e √† celle du \n",
      "gouvernement genevois, refuse la d√©marche au nom de l'autonomie communale.\n",
      "\n",
      "La ville de Gen√®ve reste toutefois subdivis√©e en quatre secteurs : La Cit√©, Plainpalais, Les \n",
      "Eaux-Vives et Le Petit-Saconnex. Alors que l'Office f√©d√©ral de la statistique (OFS) recense au \n",
      "niveau f√©d√©ral les communes en Suisse, c'est l'administration cantonale genevoise qui se charge \n",
      "du d√©coupage des communes genevoises (sous-secteurs).\n",
      "\n",
      "\n",
      "EN_TEXT:\n",
      "The municipality of Geneva took its current form in 1930, at the time of the merger of the municipalities of Geneva (Geneva-City), Plainpalais, Eaux-Vives, and Petit-Saconnex. A project to abolish the municipality and place the city under the canton's tutelage was rejected by the people of Geneva in December 1926. After the merger, four districts (named after the former municipalities) were maintained until 1958, when they were abolished due to the depletion of the city center and the relocation of the population to its outskirts.\n",
      "\n",
      "At the beginning of the 21st century, it appears that a clear distinction between the tasks of the city and those of the canton is still not clearly implemented. In this context, the State Council proposed in 1999 a merger between the city and the canton. However, the city, managed by a left-wing majority opposed to that of the Genevan government, rejected the approach in the name of municipal autonomy.\n",
      "\n",
      "The city of Geneva is still divided into four sectors: La Cit√©, Plainpalais, Les Eaux-Vives, and Le Petit-Saconnex. While the Federal Office of Statistics (FSO) counts the municipalities in Switzerland at the federal level, it is the Genevan cantonal administration that is responsible for the subdivision of the Genevan municipalities (sub-sectors).\n",
      "\n",
      "SUMMARY_EN_TEXT:\n",
      "The municipality of Geneva, formed in 1930 and currently divided into four sectors, remains distinct and autonomous from the canton, despite proposals for a merger that would place the city under the canton's administration.\n",
      "\n",
      "LANG:\n",
      "The language of the text is French.\n",
      "\n",
      "BULLETS_LANG_TEXT:\n",
      "- La municipalit√© de Gen√®ve a √©t√© form√©e en 1930.\n",
      "- Actuellement, Gen√®ve est divis√©e en quatre secteurs.\n",
      "- Celle-ci reste distincte et autonome du canton.\n",
      "- Cela est le cas malgr√© les propositions de fusion.\n",
      "- Ces propositions viseraient √† placer la ville sous l'administration du canton.\n",
      "- La ville de Gen√®ve n'est pas sous l'administration du canton malgr√© ces propositions.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "raw_text = \"\"\"\n",
    "La commune de Gen√®ve s'est constitu√©e sous sa forme actuelle en 1930, au moment de la fusion des \n",
    "communes de Gen√®ve (Gen√®ve-Cit√©), de Plainpalais, des Eaux-Vives et du Petit-Saconnex. Un projet \n",
    "supprimant la commune et mettant la ville sous la tutelle du canton √©choue devant le peuple genevois \n",
    "en d√©cembre 1926. Apr√®s la fusion, quatre arrondissements (portant les noms des anciennes communes)\n",
    "sont maintenus jusqu'en 1958, date √† laquelle, avec le processus de d√©peuplement du centre de la\n",
    "ville et de d√©placement de la population √† sa p√©riph√©rie, ils sont supprim√©s.\n",
    "\n",
    "Il appara√Æt, au d√©but du xxie si√®cle, qu'une distinction des t√¢ches de la ville et de celles du \n",
    "canton n'est toujours pas clairement r√©alis√©e. Dans ce contexte, le Conseil d'√âtat propose en 1999 \n",
    "une fusion entre ville et canton mais la ville, g√©r√©e par une majorit√© de gauche oppos√©e √† celle du \n",
    "gouvernement genevois, refuse la d√©marche au nom de l'autonomie communale.\n",
    "\n",
    "La ville de Gen√®ve reste toutefois subdivis√©e en quatre secteurs : La Cit√©, Plainpalais, Les \n",
    "Eaux-Vives et Le Petit-Saconnex. Alors que l'Office f√©d√©ral de la statistique (OFS) recense au \n",
    "niveau f√©d√©ral les communes en Suisse, c'est l'administration cantonale genevoise qui se charge \n",
    "du d√©coupage des communes genevoises (sous-secteurs).\n",
    "\"\"\"\n",
    "\n",
    "output = overall_chain(raw_text)\n",
    "for key, value in output.items():\n",
    "    print(f\"{key.upper()}:\\n{value}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Router Chains\n",
    "\n",
    "- In many cases, we may want to decide which component to run after a first component based on the output of the first component.\n",
    "- For instance, a first component could be sentiment analysis.\n",
    "  - If the sentiment is positive: run a component that uses enthusiastic language to respond.\n",
    "  - If the sentiment is negative: run a component that uses succinct but empathetic language to respond.\n",
    "- A `LLMRouterChain` can be used exactly for this purpose.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_detection = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Determine if the content of this message is Positive or Negative.\n",
    "\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt_template_positive = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Write a reply to this message by using an enthusiastic language including emojis.\n",
    "\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "prompt_template_negative = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Write a reply to this message by using a succinct but empathetic language.\n",
    "\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\": \"positive_reply\",\n",
    "        \"description\": \"Good for replying to positive messages\",\n",
    "        \"prompt_template\": prompt_template_positive,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"negative_reply\",\n",
    "        \"description\": \"Good for replying to negative messages\",\n",
    "        \"prompt_template\": prompt_template_negative,\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "destination_chains = dict()\n",
    "\n",
    "for p in prompt_infos:\n",
    "    destination_chains[p[\"name\"]] = LLMChain(llm=chat_model, prompt=p[\"prompt_template\"])\n",
    "    \n",
    "destinations = [f\"{p['name']}: {p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This will be used when the router cannot decide if it's a Positive or Negative\n",
    "\n",
    "default_prompt = ChatPromptTemplate.from_template(\n",
    "    \"\"\"\n",
    "    Write a reply to this message in succinct and generic terms.\n",
    "\n",
    "    {input}\n",
    "    \"\"\"\n",
    ")\n",
    "    \n",
    "default_chain = LLMChain(llm=chat_model, prompt=default_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template_router = \"\"\"\n",
    "Given a message, select the model prompt best suited for replying to it.\n",
    "You will be given the names of the available prompts and a description of what the prompt is best \n",
    "suited for.\n",
    "\n",
    "<< FORMATTING >>\n",
    "Return a markdown code snippet with a JSON object formatted to look like:\n",
    "```json\n",
    "{{{{\n",
    "    \"destination\": string \\ name of the prompt to use or \"DEFAULT\"\n",
    "    \"next_inputs\": string \\ a potentially modified version of the original input (e.g. fix typos)\n",
    "}}}}\n",
    "```\n",
    "\n",
    "REMEMBER: \"destination\" MUST be one of the candidate prompt\n",
    "names specified below OR it can be \"DEFAULT\" if the input is not\n",
    "well suited for any of the candidate prompts.\n",
    "REMEMBER: \"next_inputs\" can just be the original input \\\n",
    "if you don't think any modifications are needed.\n",
    "\n",
    "<< CANDIDATE PROMPTS >>\n",
    "{destinations}\n",
    "\n",
    "<< INPUT >>\n",
    "{{input}}\n",
    "\n",
    "<< OUTPUT (remember to include the ```json in the beginning and the ``` at the end)>>\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = prompt_template_router.format(\n",
    "    destinations=destinations_str\n",
    ")\n",
    "router_prompt = PromptTemplate(\n",
    "    template=router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser(),\n",
    ")\n",
    "\n",
    "router_chain = LLMRouterChain.from_llm(chat_model, router_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = MultiPromptChain(\n",
    "    router_chain=router_chain, \n",
    "    destination_chains=destination_chains, \n",
    "    default_chain=default_chain,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/casalegn/dev/LangChain-Experiments/tmp-venv/lib/python3.11/site-packages/langchain/chains/llm.py:280: UserWarning: The predict_and_parse method is deprecated, instead pass an output parser directly to LLMChain.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive_reply: {'input': 'I am so happy today! I just got a new job and I am going to start next week.'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "Wow, that's amazing news! üòç Huge congratulations on your new job! üëèüëè I'm absolutely thrilled for you! üíÉüéâ Best of luck for your journey ahead! Let's celebrate this fantastic achievement! ü•≥üçæ\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\n",
    "    \"\"\"\n",
    "    I am so happy today! I just got a new job and I am going to start next week.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "negative_reply: {'input': \"My dog broke his leg and I am so sad. I don't know what to do.\"}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n",
      "I'm really sorry to hear about your dog. It's understandable you're feeling this way. Please take him to a vet as soon as possible for a professional assessment. Everything will be okay, and remember he needs your strength and love in this challenging time.\n"
     ]
    }
   ],
   "source": [
    "response = chain.run(\n",
    "    \"\"\"\n",
    "    My dog broke his leg and I am so sad. I don't know what to do.\n",
    "    \"\"\"\n",
    ")\n",
    "\n",
    "print(response)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tmp-venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
